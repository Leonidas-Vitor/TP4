{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import os\n",
    "from bson.json_util import dumps\n",
    "\n",
    "def GetCollectionData(database: str, collection: str):\n",
    "    uri = os.environ.get(\"MONGODB_URI\")\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    db = client[database]\n",
    "    collection = db[collection]\n",
    "\n",
    "    documents = list(collection.find())\n",
    "\n",
    "    for document in documents:\n",
    "        document.pop('_id', None)\n",
    "\n",
    "    json_data = dumps(documents)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "stockPrices = GetCollectionData(\"Stocks\", \"Prices\")\n",
    "stockPrices = pd.read_json(stockPrices)\n",
    "stockPrices.to_csv(\"data/stockPrices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockInfo = GetCollectionData(\"Stocks\", \"Info\")\n",
    "stockInfo = pd.read_json(stockInfo)\n",
    "stockInfo.to_csv(\"data/stockInfo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolarPrices = GetCollectionData(\"Indicators\", \"Dollar\")\n",
    "dolarPrices = pd.read_json(dolarPrices)\n",
    "dolarPrices.to_csv(\"data/dollar.csv\", index=False)\n",
    "\n",
    "ipcaPrices = GetCollectionData(\"Indicators\", \"IPCA\")\n",
    "ipcaPrices = pd.read_json(ipcaPrices)\n",
    "ipcaPrices.to_csv(\"data/ipca.csv\", index=False)\n",
    "\n",
    "selicPrices = GetCollectionData(\"Indicators\", \"SELIC\")\n",
    "selicPrices = pd.read_json(selicPrices)\n",
    "selicPrices.to_csv(\"data/selic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Quais são os benefícios de trabalhar com modelos de linguagem grandes?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=100)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Configuração\n",
    "model_name = \"gpt2\"  # Nome do modelo\n",
    "seed = 10  # Para resultados reproduzíveis\n",
    "\n",
    "# Inicializando o pipeline de geração de texto\n",
    "generator = pipeline(\"text-generation\", model=model_name)\n",
    "set_seed(seed)\n",
    "\n",
    "# Entrada do usuário\n",
    "prompt = \"Quais são os benefícios de trabalhar com modelos de linguagem grandes?\"\n",
    "\n",
    "# Gerar texto\n",
    "output = generator(prompt, truncation=True, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# Exibir o resultado\n",
    "for i, text in enumerate(output):\n",
    "    print(f\"Texto gerado {i + 1}:\")\n",
    "    print(text[\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(message: str) -> dict:\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2-large\")\n",
    "    return generator(message)\n",
    "\n",
    "\n",
    "message = \"What are the benefits of working with large language models?\"\n",
    "response = gpt(message)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
