{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESOLVER PROBLEMA DA VARIÁVEL DE AMBIENTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Identificação e Escolha do Modelo LLM (Local):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo                             | Desempenho                              | Custo Computacional Local              | Acessibilidade Local |\n",
    "|------------------------------------|-----------------------------------------|----------------------------------------|----------------------|\n",
    "| gpt2                               | 2.6s mas não respondeu adequadamente    | Custo mínimo                           | Acessível            |\n",
    "| bigscience/bloom-560m              | 12s resposta estranha, mas não alucinou | Custo mínimo                           | Acessível            |\n",
    "| TinyLlama/TinyLlama-1.1B-Chat-v1.0 | 3min e 11 com uma resposta adequada     | Necessidade de mais de 8GB de memória  | Acessível            |\n",
    "| gpt2-large                         | 8,6 mas não respondeu adequadamente     | Custo mínimo                           | Acessível            |\n",
    "| EleutherAI/gpt-neo-1.3B            | Não rodou localmente                    | Necessidade de mais de 24GB de memória | Acessível            |\n",
    "| tiiuae/falcon-7b                   | Não rodou localmente                    | Necessidade de mais de 12GB de memória | Acessível            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R.:** Considerando apenas as opções que rodaram localmente e a qualidade das respostas, o TinyLlama-1.1B foi escolhido, pois, apesar demorar mais para responder, a sua resposta foi mais assertiva, compensando seu maior custo computacional para ser usada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Integração de LLM com FastAPI no Ambiente Local:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uvicorn main:api --reload --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_stocks_valorization(ticker):\n",
    "    url = 'http://127.0.0.1:8000/stock/valorization'\n",
    "    response = requests.get(url, params={'ticker': ticker})\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def get_dollar_valorization():\n",
    "    url = 'http://127.0.0.1:8000/indicators/dollar/valorization/'\n",
    "    response = requests.get(url,)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def get_response(msg : str, data):\n",
    "    url = 'http://127.0.0.1:8000/llm/question'\n",
    "    response = requests.get(url,params={'question':msg, 'data': data})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MENSAGEM PARA A API\n",
    "msg = 'This stock is a the good investment?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sJson = json.loads(get_stocks_valorization('PETR4.SA'))\n",
    "djson = json.loads(get_dollar_valorization())\n",
    "\n",
    "#Foi necessário reduzir o tamanho do json para 6 meses para não exceder o limite de tokens\n",
    "#Reduzido para 1 mês para respostas mais rápidas\n",
    "stock_last_6_months = pd.DataFrame(sJson).astype(str).tail(1).to_dict(orient='list')\n",
    "dollar_last_6_months = pd.DataFrame(djson).astype(str).tail(1).to_dict(orient='list')\n",
    "\n",
    "#Tempo médio de resposta: 8 a 10 mins com 6 meses\n",
    "#Tempo médio de resposta: 2 a 3 min com 1 mês\n",
    "response = get_response(msg, {'stock': stock_last_6_months, 'dollar': dollar_last_6_months})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'This stock is a good investment',\n",
       " 'confidence': 90,\n",
       " 'justification': 'The company has a strong financial position, a solid management team, and a proven track record of growth and profitability. Additionally, the stock has been trading at a discount to its peers, making it an attractive investment opportunity.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fora da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed\n",
    "import torch\n",
    "\n",
    "def llama(question: str, data):\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    pipe = pipeline(\"text-generation\",\n",
    "                    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "                    torch_dtype=torch.bfloat16,\n",
    "                    device=device)\n",
    "    message = [\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": \"You are a investiment advisor, and you have to answer the following question:\"},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": question},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": f'''Answer the question above using the data below: {data}'''},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": \n",
    "            '''You must return the answer in json format, with the following structure: \n",
    "            {\n",
    "                'answer': 'your answer here',\n",
    "                'confidence': 'your confidence here',\n",
    "                'justification': 'your short justification here',\n",
    "            }\n",
    "            '''}\n",
    "        ]\n",
    "\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        message,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "\n",
    "    prediction = pipe(prompt,\n",
    "                    max_new_tokens=1000,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.2, top_k=50, top_p=0.95)\n",
    "\n",
    "    generated_text = prediction[0]['generated_text']\n",
    "\n",
    "\n",
    "    response = generated_text[len(prompt):].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempo médio para resposta: 8 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|assistant|>\n",
      "Here's an example of how to return the answer and confidence in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"answer\": \"This stock is a good investment.\",\n",
      "    \"confidence\": 90,\n",
      "    \"justification\": \"The data provided in the question and the stock data show that this stock is valued at $5.6615 and has a year-month valuation of 2024-07. The valuation is higher than the current market price of $5.6615, indicating that this stock is a good investment opportunity.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "sJson = json.loads(get_stocks_valorization('PETR4.SA'))\n",
    "\n",
    "dollar_json = json.loads(get_dollar_valorization())\n",
    "\n",
    "notebook_response = llama(msg, {'stock': pd.DataFrame(sJson).astype(str).tail(1).to_dict(orient='list'), 'dollar': pd.DataFrame(dollar_json).astype(str).tail(1).to_dict(orient='list')})\n",
    "\n",
    "print(notebook_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'This stock is a good investment.',\n",
       " 'confidence': 90,\n",
       " 'justification': 'The data provided in the question and the stock data show that this stock is valued at $5.6615 and has a year-month valuation of 2024-07. The valuation is higher than the current market price of $5.6615, indicating that this stock is a good investment opportunity.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Notebook_response_clean = json.loads('{' + notebook_response.split(\"{\")[1].split(\"}\")[0] +'}')\n",
    "Notebook_response_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
